{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imu_kalman.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsuzrKgTO-MN"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "import gc\n",
        "import json\n",
        "from PIL import Image\n",
        "import geoplot\n",
        "import geopandas as gpd\n",
        "from tqdm import tqdm\n",
        "from scipy.fft import fft, ifft\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data parsing/aligning to timestamps\n",
        "(data source: https://www.kaggle.com/c/indoor-location-navigation/data)\n",
        "(helper functions: https://github.com/location-competition/indoor-location-competition-20)"
      ],
      "metadata": {
        "id": "YX6cfK21WmRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after reviewing,implementation rotation to original coordinates may be \n",
        "#erroneous, please refer to library documentation:\n",
        "#ahrs.readthedocs.io/ -- library used for kalman filtering, also has other useful algorithms"
      ],
      "metadata": {
        "id": "DCivrs_CZtDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = \"../input/indoor-location-navigation/train\"\n",
        "metadata_root = \"../input/indoor-location-navigation/metadata\"\n",
        "state = \"5d2709e003f801723c32d896\"\n",
        "floor = \"F2\"\n",
        "\n",
        "def list_files(startpath):\n",
        "    \"\"\"Show directory structure recursive like tree command.\n",
        "    refered from https://stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python\n",
        "    \"\"\"\n",
        "    file_list = []\n",
        "    for root, dirs, files in os.walk(startpath):\n",
        "        for f in files:\n",
        "#             pathname_curr = startpath+ \"/\"+os.path.basename(root)+\"/\"+f\n",
        "            pathname_curr = startpath+\"/\"+f\n",
        "            \n",
        "            file_list.append(pathname_curr)\n",
        "    return file_list\n",
        "\n",
        "path_building_curr = data_root + \"/\" + state + \"/\" + floor\n",
        "# path_building_curr_test = data_root + \"/\" + state + \"/\" + floor_test\n",
        "\n",
        "filelistcurr= list_files(path_building_curr)\n",
        "# filelistcurr_test= list_files(path_building_curr_test)\n",
        "\n",
        "# filelistcurr"
      ],
      "metadata": {
        "id": "y7L477r7VduL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "acce_ = {}\n",
        "gyro_ = {}\n",
        "magn_ = {}\n",
        "ahrs_ = {}\n",
        "wifi_ = {}\n",
        "ibeacon_ = {}\n",
        "waypoint_ = {}\n",
        "filename_biggest_wifi = {}\n",
        "for data_filename in filelistcurr:\n",
        "    acce = []\n",
        "    gyro = []\n",
        "    magn = []\n",
        "    ahrs = []\n",
        "    wifi = []\n",
        "    ibeacon = []\n",
        "    waypoint = []\n",
        "    with open(data_filename, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line_data in lines:\n",
        "        line_data = line_data.strip()\n",
        "        if not line_data or line_data[0] == '#':\n",
        "            continue\n",
        "\n",
        "        line_data = line_data.split('\\t')\n",
        "\n",
        "        if line_data[1] == 'TYPE_ACCELEROMETER':\n",
        "            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
        "            continue\n",
        "        if line_data[1] == 'TYPE_GYROSCOPE':\n",
        "            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
        "            continue\n",
        "        if line_data[1] == 'TYPE_MAGNETIC_FIELD':\n",
        "            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
        "            continue\n",
        "        if line_data[1] == 'TYPE_ROTATION_VECTOR':\n",
        "            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
        "            continue\n",
        "        if line_data[1] == 'TYPE_WIFI':\n",
        "            sys_ts = line_data[0]\n",
        "            ssid = line_data[2]\n",
        "            bssid = line_data[3]\n",
        "            rssi = line_data[4]\n",
        "            lastseen_ts = line_data[6]\n",
        "            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]\n",
        "            wifi.append(wifi_data)\n",
        "            continue\n",
        "        if line_data[1] == 'TYPE_BEACON':\n",
        "            ts = line_data[0]\n",
        "            uuid = line_data[2]\n",
        "            major = line_data[3]\n",
        "            minor = line_data[4]\n",
        "            rssi = line_data[6]\n",
        "            dist = line_data[7]\n",
        "            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi, dist]\n",
        "            ibeacon.append(ibeacon_data)\n",
        "            continue\n",
        "\n",
        "        if line_data[1] == 'TYPE_WAYPOINT':\n",
        "            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])\n",
        "\n",
        "    acce_[data_filename] = np.array(acce)\n",
        "    gyro_[data_filename] = np.array(gyro)\n",
        "    magn_[data_filename] = np.array(magn)\n",
        "    ahrs_[data_filename] = np.array(ahrs)\n",
        "    wifi_[data_filename] = np.array(wifi)\n",
        "    ibeacon_[data_filename] = np.array(ibeacon)\n",
        "    waypoint_[data_filename] = np.array(waypoint)\n",
        "    filename_biggest_wifi[data_filename] = len(wifi)"
      ],
      "metadata": {
        "id": "mUG5mhvxVTch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_wifi_file, test_wifi_file = sorted(filename_biggest_wifi, key=filename_biggest_wifi.get, reverse=True)[:2]\n",
        "# filename_biggest_wifi\n",
        "train_wifi = wifi_[train_wifi_file]\n",
        "test_wifi = wifi_[test_wifi_file]"
      ],
      "metadata": {
        "id": "ONFvrdeRVacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ibeacon = ibeacon_[train_wifi_file]"
      ],
      "metadata": {
        "id": "70Pe79nuVkXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wifi_df_verbose= pd.DataFrame(train_wifi, columns = ['timestamp', 'ssid', 'bssid', 'rssi', 'lastseen_ts'])\n",
        "wifi_df_verbose_test= pd.DataFrame(test_wifi, columns = ['timestamp', 'ssid', 'bssid', 'rssi', 'lastseen_ts'])\n",
        "wifi_df_verbose = wifi_df_verbose.drop(labels=['ssid','lastseen_ts'],axis=1)\n",
        "\n",
        "ibeacon_df_verbose= pd.DataFrame(train_ibeacon, columns = ['timestamp', 'beaconId', 'rssi', 'distance'])\n"
      ],
      "metadata": {
        "id": "bv-mRO25Vlt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = train_wifi_file\n",
        "\n",
        "acce = pd.DataFrame(acce_[train_file], columns=[\"timestamp\", \"acc_x\", \"acc_y\", \"acc_z\"])\n",
        "gyro = pd.DataFrame(gyro_[train_file], columns=[\"timestamp\", \"gyro_x\", \"gyro_y\", \"gyro_z\"])\n",
        "magn = pd.DataFrame(magn_[train_file], columns=[\"timestamp\", \"magn_x\", \"magn_y\", \"magn_z\"])\n",
        "ahrs = pd.DataFrame(ahrs_[train_file], columns=[\"timestamp\", \"ahrs_x\", \"ahrs_y\", \"ahrs_z\"])\n",
        "data_sens_df = (\n",
        "    acce.merge(gyro, on=\"timestamp\")\n",
        "    .merge(magn, on=\"timestamp\")\n",
        "    .merge(ahrs, on=\"timestamp\")\n",
        ")\n",
        "data_sens_df[\"timestamp\"] = data_sens_df[\"timestamp\"].astype(int)\n",
        "\n",
        "test_file = test_wifi_file\n",
        "\n",
        "acce_test = pd.DataFrame(acce_[test_file], columns=[\"timestamp\", \"acc_x\", \"acc_y\", \"acc_z\"])\n",
        "gyro_test = pd.DataFrame(gyro_[test_file], columns=[\"timestamp\", \"gyro_x\", \"gyro_y\", \"gyro_z\"])\n",
        "magn_test = pd.DataFrame(magn_[test_file], columns=[\"timestamp\", \"magn_x\", \"magn_y\", \"magn_z\"])\n",
        "ahrs_test = pd.DataFrame(ahrs_[test_file], columns=[\"timestamp\", \"ahrs_x\", \"ahrs_y\", \"ahrs_z\"])\n",
        "data_sens_df_test = (\n",
        "    acce_test.merge(gyro_test, on=\"timestamp\")\n",
        "    .merge(magn_test, on=\"timestamp\")\n",
        "    .merge(ahrs_test, on=\"timestamp\")\n",
        ")\n",
        "data_sens_df_test[\"timestamp\"] = data_sens_df_test[\"timestamp\"].astype(int)\n",
        "\n"
      ],
      "metadata": {
        "id": "QM2dOxE5VtBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waypoint_df = pd.DataFrame(waypoint_[train_wifi_file],columns=[\"timestamp\",\"x\",\"y\",])\n",
        "waypoint_df[\"timestamp\"] = waypoint_df[\"timestamp\"].astype(int)\n",
        "waypoint_df[\"x\"] = waypoint_df[\"x\"].astype(float)\n",
        "waypoint_df[\"y\"] = waypoint_df[\"y\"].astype(float)\n",
        "\n",
        "waypoint_df_test = pd.DataFrame(waypoint_[test_wifi_file],columns=[\"timestamp\",\"x\",\"y\",])\n",
        "waypoint_df_test[\"timestamp\"] = waypoint_df_test[\"timestamp\"].astype(int)\n",
        "waypoint_df_test[\"x\"] = waypoint_df_test[\"x\"].astype(float)\n",
        "waypoint_df_test[\"y\"] = waypoint_df_test[\"y\"].astype(float)\n"
      ],
      "metadata": {
        "id": "rPzlz_pnV0XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addtimestamps(data_df_,waypoint_df_):\n",
        "    a_ = data_df_['timestamp'].values\n",
        "    bh_ = waypoint_df_['timestamp'].values\n",
        "    bl_ = waypoint_df_['timestamp'].values\n",
        "    bl_ = np.insert(bl_, 0, 0, axis=0)\n",
        "    last_, bl_ = bl_[-1], bl_[:-1]\n",
        "\n",
        "    i_, j_ = np.where((a_[:, None] >= bl_) & (a_[:, None] <= bh_))\n",
        "\n",
        "    df_pts_ = pd.DataFrame(\n",
        "        np.column_stack([data_df_.values[i_], waypoint_df_[['x','y']].values[j_]]),\n",
        "        columns=data_df_.columns.append(waypoint_df_.columns[1:3])\n",
        "    )\n",
        "    return df_pts_"
      ],
      "metadata": {
        "id": "oWUXxb8XV6Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sens_df_merged = addtimestamps(data_sens_df, waypoint_df)#data_sens_df.merge(waypoint_df,how='outer',left_index=True,right_index=True)\n",
        "sens_ground_truth = data_sens_df_merged[['x','y']]\n",
        "data_sens_df_merged = data_sens_df_merged.drop(labels=['x','y'],axis=1)\n",
        "\n",
        "data_sens_df_merged_test = addtimestamps(data_sens_df_test, waypoint_df_test)#data_sens_df_test.merge(waypoint_df_test,how='outer',left_index=True,right_index=True)\n",
        "sens_ground_truth_test = data_sens_df_merged_test[['x','y']]\n",
        "data_sens_df_merged_test = data_sens_df_merged_test.drop(labels=['x','y'],axis=1)\n"
      ],
      "metadata": {
        "id": "0pTYDrf7V9qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xpos_initial = sens_ground_truth['x'][0]\n",
        "ypos_initial = sens_ground_truth['y'][0]"
      ],
      "metadata": {
        "id": "5PKii5qFWFc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ahrs.common.quaternion import QuaternionArray\n",
        "gyr_arr = data_sens_df_merged[['gyro_x','gyro_y','gyro_z']].values\n",
        "acce_arr = data_sens_df_merged[['acc_x','acc_y','acc_z']].values\n",
        "magn_arr = data_sens_df_merged[['magn_x','magn_y','magn_z']].values\n",
        "\n",
        "# ekf_estimator = EKF(gyr=gyr_arr, acc=acce_arr,mag=magn_arr, frequency=50.0,q0=qtn.Quaternion([1,0,0,0]))\n",
        "ekf_estimator = EKF(gyr=gyr_arr, acc=acce_arr,mag=magn_arr, frequency=50.0)\n",
        "\n",
        "#quaternion positions\n",
        "quaternion_estimates = QuaternionArray(ekf_estimator.Q)\n",
        "#convert from quaternion to euler angles\n",
        "eu_angles = quaternion_estimates.to_angles()\n",
        "\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "poslistx = []\n",
        "poslisty = []\n",
        "poslistz = []\n",
        "\n",
        "x=xpos_initial\n",
        "y=ypos_initial\n",
        "z=0\n",
        "counter = 0\n",
        "for i in quaternion_estimates:\n",
        "    posnew = qtn.Quaternion(i).rotate([xpos_initial,ypos_initial,0])\n",
        "    x = posnew[0]\n",
        "    y = posnew[1]\n",
        "    z = posnew[2]\n",
        "    poslistx.append(x)\n",
        "    poslisty.append(y) \n",
        "    poslistz.append(z) \n",
        "poslistx = np.array(poslistx)\n",
        "poslisty = np.array(poslisty)\n",
        "poslistz = np.array(poslistz)"
      ],
      "metadata": {
        "id": "HsB75yWEWIq2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}